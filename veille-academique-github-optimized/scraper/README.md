# ğŸ” Scraper - Modules Python

## Description
Modules Python pour le scraping automatisÃ© des sources acadÃ©miques, avec gestion intelligente des erreurs et scoring de pertinence.

## ğŸ”§ Installation

### PrÃ©requis
- Python 3.11+
- Chrome/Chromium (pour Selenium)

### Ã‰tapes d'Installation
```bash
# 1. Installer les dÃ©pendances
pip install -r requirements.txt

# 2. Installer ChromeDriver (automatique avec selenium)
# Ou tÃ©lÃ©charger manuellement depuis https://chromedriver.chromium.org/
```

## âš™ï¸ Configuration

### Fichier config.py
Personnaliser les paramÃ¨tres :
```python
# Mots-clÃ©s de recherche
KEYWORDS = [
    "blockchain", "cryptocurrency", "governance",
    # Ajouter vos termes spÃ©cialisÃ©s
]

# Sources Ã  scraper
SOURCES = {
    "academic_positions": {
        "url": "https://academicpositions.com",
        "active": True
    },
    # Ajouter vos sources
}

# ParamÃ¨tres de scraping
SCRAPING_CONFIG = {
    "delay_between_requests": 2,  # secondes
    "max_retries": 3,
    "timeout": 30
}
```

## ğŸš€ Utilisation

### Scraping Basique
```bash
# Scraper toutes les sources
python scraper.py

# Scraper des sources spÃ©cifiques
python scraper.py --sources academic_positions euraxess

# Utiliser des mots-clÃ©s personnalisÃ©s
python scraper.py --keywords blockchain governance crypto
```

### Scraping ProgrammÃ©
```python
from scraper import JobScraper

# CrÃ©er une instance
scraper = JobScraper()

# Lancer le scraping
results = scraper.scrape_all_sources()

# Sauvegarder les rÃ©sultats
scraper.save_results(results, format='json')
```

## ğŸ“ Structure

```
scraper/
â”œâ”€â”€ config.py                    # Configuration principale
â”œâ”€â”€ scraper.py                   # Scraper principal
â”œâ”€â”€ specialized_scrapers.py      # Scrapers spÃ©cialisÃ©s
â”œâ”€â”€ requirements.txt             # DÃ©pendances Python
â”œâ”€â”€ results/                     # RÃ©sultats de scraping
â”‚   â”œâ”€â”€ jobs_YYYY-MM-DD.json    # DonnÃ©es JSON
â”‚   â””â”€â”€ jobs_YYYY-MM-DD.csv     # Export CSV
â””â”€â”€ README.md                   # Cette documentation
```

## ğŸ¯ Modules Principaux

### scraper.py
Classe principale `JobScraper` :
- Gestion des sources multiples
- Rate limiting automatique
- Scoring de pertinence
- Sauvegarde des rÃ©sultats

### specialized_scrapers.py
Scrapers spÃ©cialisÃ©s pour :
- Academic Positions EU
- Euraxess
- Galaxie/OdyssÃ©e
- Sites d'Ã©coles spÃ©cifiques

### config.py
Configuration centralisÃ©e :
- 54 sources acadÃ©miques
- 42 mots-clÃ©s spÃ©cialisÃ©s
- ParamÃ¨tres de scraping

## ğŸ” FonctionnalitÃ©s AvancÃ©es

### Scoring de Pertinence
```python
def calculate_relevance_score(job_data, keywords):
    """
    Calcule un score de 0.0 Ã  1.0 basÃ© sur :
    - PrÃ©sence des mots-clÃ©s dans le titre
    - Correspondance avec la description
    - RÃ©putation de l'institution
    """
    score = 0.0
    # Algorithme de scoring...
    return score
```

### Gestion des Erreurs
- Retry automatique en cas d'Ã©chec
- Logging dÃ©taillÃ© des opÃ©rations
- Gestion des timeouts et rate limits
- Sauvegarde des erreurs pour debug

### Support Multi-Format
```python
# Sauvegarder en JSON
scraper.save_results(results, format='json')

# Sauvegarder en CSV
scraper.save_results(results, format='csv')

# Sauvegarder en base de donnÃ©es
scraper.save_to_database(results)
```

## ğŸ”§ Personnalisation

### Ajouter une Nouvelle Source
1. Ajouter l'URL dans `config.py`
2. CrÃ©er un scraper spÃ©cialisÃ© dans `specialized_scrapers.py`
3. Tester avec `python scraper.py --sources nouvelle_source`

### Modifier les Mots-ClÃ©s
```python
# Dans config.py
CUSTOM_KEYWORDS = [
    "votre_domaine_specifique",
    "technologie_emergente",
    "methodologie_recherche"
]
```

### Ajuster le Scoring
Modifier la fonction `calculate_relevance_score()` pour :
- PondÃ©rer diffÃ©remment les critÃ¨res
- Ajouter de nouveaux facteurs
- Personnaliser pour votre domaine

## ğŸ“Š RÃ©sultats

### Format JSON
```json
{
  "title": "Postdoc in Blockchain Research",
  "institution": "KU Leuven",
  "location": "Belgium",
  "type": "Postdoc",
  "deadline": "2025-08-18",
  "url": "https://...",
  "relevance_score": 0.95,
  "keywords_found": ["blockchain", "governance"],
  "scraped_at": "2025-06-18T15:30:00Z"
}
```

### Statistiques
- Nombre total d'offres trouvÃ©es
- RÃ©partition par type de poste
- Scores de pertinence moyens
- Sources les plus productives

## ğŸ› DÃ©pannage

### Erreur : "ChromeDriver not found"
```bash
# Installer ChromeDriver
pip install webdriver-manager
```

### Erreur : "Rate limited"
Augmenter le dÃ©lai dans `config.py` :
```python
SCRAPING_CONFIG["delay_between_requests"] = 5
```

### Erreur : "Timeout"
Augmenter le timeout :
```python
SCRAPING_CONFIG["timeout"] = 60
```

## ğŸ“ˆ Performance

### Optimisations
- Scraping parallÃ¨le (avec prudence)
- Cache des rÃ©sultats rÃ©cents
- Scraping incrÃ©mental
- Filtrage prÃ©coce des rÃ©sultats

### Monitoring
```bash
# Logs dÃ©taillÃ©s
python scraper.py --verbose

# Mode debug
python scraper.py --debug
```

